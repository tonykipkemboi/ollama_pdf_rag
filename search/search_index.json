{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Ollama PDF RAG","text":"<p>Chat with your PDFs locally using Ollama and LangChain</p> <p>Welcome to the documentation for Ollama PDF RAG \u2014 a powerful, privacy-first application that lets you have conversations with your PDF documents using local language models.</p> <p></p>"},{"location":"#why-ollama-pdf-rag","title":"\ud83c\udf1f Why Ollama PDF RAG?","text":"Feature Benefit \ud83d\udd12 100% Local Your data never leaves your machine \ud83d\ude80 Two UIs Modern Next.js app OR classic Streamlit \ud83d\udcc4 Multi-PDF Support Query across multiple documents \ud83e\udde0 Smart Retrieval Multi-query expansion for better results \u26a1 Fast API FastAPI backend for production use \ud83c\udfaf Thinking Models Special support for qwen3, deepseek-r1"},{"location":"#architecture-overview","title":"\ud83c\udfd7\ufe0f Architecture Overview","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        USER INTERFACE                        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     Next.js (Modern UI)     \u2502      Streamlit (Classic)      \u2502\n\u2502     localhost:3000          \u2502      localhost:8501           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2502\n                              \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                      FastAPI Backend                         \u2502\n\u2502                      localhost:8001                          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  PDF Upload  \u2502  RAG Query   \u2502   Models     \u2502   Health       \u2502\n\u2502  /api/v1/    \u2502  /api/v1/    \u2502   /api/v1/   \u2502   /health      \u2502\n\u2502  pdfs        \u2502  query       \u2502   models     \u2502                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2502\n          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n          \u25bc                   \u25bc                   \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   ChromaDB      \u2502 \u2502    Ollama       \u2502 \u2502    SQLite       \u2502\n\u2502   (Vectors)     \u2502 \u2502    (LLM)        \u2502 \u2502    (Metadata)   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"#quick-start","title":"\ud83d\ude80 Quick Start","text":"<pre><code># 1. Clone and install\ngit clone https://github.com/tonykipkemboi/ollama_pdf_rag.git\ncd ollama_pdf_rag\npython -m venv .venv &amp;&amp; source .venv/bin/activate\npip install -r requirements.txt\n\n# 2. Install Ollama models\nollama pull llama3.2\nollama pull nomic-embed-text\n\n# 3. Start the app (Next.js UI + FastAPI)\n./start_all.sh\n# Or manually:\n# python run_api.py &amp;\n# cd web-ui &amp;&amp; pnpm dev\n\n# 4. Open http://localhost:3000\n</code></pre>"},{"location":"#screenshots","title":"\ud83d\udcf8 Screenshots","text":""},{"location":"#nextjs-modern-interface","title":"Next.js Modern Interface","text":""},{"location":"#streamlit-classic-interface","title":"Streamlit Classic Interface","text":""},{"location":"#documentation","title":"\ud83d\udcd6 Documentation","text":"Section Description Installation Full setup guide Quick Start Get running in 5 minutes PDF Processing How documents are processed RAG Pipeline Understanding retrieval Chat Interface Using the UIs API Reference Backend API docs Contributing How to contribute"},{"location":"#key-features","title":"\ud83d\udd27 Key Features","text":""},{"location":"#pdf-selection-chat","title":"PDF Selection &amp; Chat","text":"<ul> <li>\u2611\ufe0f Checkbox Selection: Select PDFs before chatting</li> <li>\ud83d\udd0d Question Classification: Auto-detects if you need documents</li> <li>\ud83d\udcac General Chat: Works without documents too</li> <li>\ud83d\udcda Multi-PDF: Query across multiple documents</li> </ul>"},{"location":"#rag-pipeline","title":"RAG Pipeline","text":"<ul> <li>\ud83d\udd04 Multi-Query Retrieval: Generates alternative queries</li> <li>\ud83e\udde9 Smart Chunking: 7500 char chunks with 100 overlap</li> <li>\ud83c\udfaf Source Citations: Every answer includes sources</li> <li>\ud83e\udde0 Chain-of-Thought: Thinking models show reasoning</li> </ul>"},{"location":"#developer-experience","title":"Developer Experience","text":"<ul> <li>\ud83d\udcdd Type Safe: Full TypeScript frontend</li> <li>\ud83e\uddea Tested: Python tests with pytest</li> <li>\ud83d\udd04 CI/CD: GitHub Actions for tests</li> <li>\ud83d\udcda Documented: MkDocs with full API reference</li> </ul>"},{"location":"#project-status","title":"\ud83d\udcca Project Status","text":""},{"location":"#community","title":"\ud83e\udd1d Community","text":"<ul> <li>\ud83d\udc1b Report a Bug</li> <li>\ud83d\udca1 Request a Feature</li> <li>\ud83e\udd1d Contribute</li> <li>\u2b50 Star on GitHub</li> </ul>"},{"location":"#license","title":"\ud83d\udcc4 License","text":"<p>This project is open source under the MIT License.</p>"},{"location":"api/document/","title":"Document Processing API","text":"<p>This page documents the document processing components of Ollama PDF RAG.</p>"},{"location":"api/document/#documentprocessor","title":"DocumentProcessor","text":"<pre><code>class DocumentProcessor:\n    \"\"\"Handles PDF document loading and processing.\"\"\"\n\n    def __init__(self, chunk_size: int = 1000, chunk_overlap: int = 200):\n        \"\"\"Initialize document processor with chunking parameters.\"\"\"\n</code></pre>"},{"location":"api/document/#methods","title":"Methods","text":""},{"location":"api/document/#load_document","title":"load_document","text":"<pre><code>def load_document(self, file_path: str) -&gt; List[Document]:\n    \"\"\"Load a PDF document and return list of Document objects.\"\"\"\n</code></pre> <p>Parameters: - <code>file_path</code>: Path to the PDF file</p> <p>Returns: - List of Document objects</p>"},{"location":"api/document/#split_documents","title":"split_documents","text":"<pre><code>def split_documents(self, documents: List[Document]) -&gt; List[Document]:\n    \"\"\"Split documents into chunks with overlap.\"\"\"\n</code></pre> <p>Parameters: - <code>documents</code>: List of Document objects</p> <p>Returns: - List of chunked Document objects</p>"},{"location":"api/document/#process_pdf","title":"process_pdf","text":"<pre><code>def process_pdf(self, file_path: str) -&gt; List[Document]:\n    \"\"\"Load and process a PDF file.\"\"\"\n</code></pre> <p>Parameters: - <code>file_path</code>: Path to the PDF file</p> <p>Returns: - List of processed Document chunks</p>"},{"location":"api/document/#usage-example","title":"Usage Example","text":"<pre><code># Initialize processor\nprocessor = DocumentProcessor(chunk_size=1000, chunk_overlap=200)\n\n# Process a PDF file\ndocuments = processor.process_pdf(\"path/to/document.pdf\")\n\n# Access document content\nfor doc in documents:\n    print(doc.page_content)\n    print(doc.metadata)\n</code></pre>"},{"location":"api/document/#configuration","title":"Configuration","text":"<p>The document processor can be configured with:</p> <ul> <li><code>chunk_size</code>: Number of characters per chunk</li> <li><code>chunk_overlap</code>: Number of overlapping characters</li> <li><code>pdf_parser</code>: PDF parsing backend</li> <li><code>encoding</code>: Text encoding</li> </ul>"},{"location":"api/document/#error-handling","title":"Error Handling","text":"<p>The processor handles common errors:</p> <ul> <li>File not found</li> <li>Invalid PDF format</li> <li>Encoding issues</li> <li>Memory constraints </li> </ul>"},{"location":"api/embeddings/","title":"Embeddings API","text":"<p>This page documents the text embedding components used for semantic search.</p>"},{"location":"api/embeddings/#nomicembeddings","title":"NomicEmbeddings","text":"<pre><code>class NomicEmbeddings:\n    \"\"\"Manages text embeddings using Nomic's embedding model.\"\"\"\n\n    def __init__(self, model_name: str = \"nomic-embed-text\"):\n        \"\"\"Initialize embeddings with model name.\"\"\"\n</code></pre>"},{"location":"api/embeddings/#methods","title":"Methods","text":""},{"location":"api/embeddings/#embed_documents","title":"embed_documents","text":"<pre><code>def embed_documents(self, texts: List[str]) -&gt; List[List[float]]:\n    \"\"\"Generate embeddings for a list of texts.\"\"\"\n</code></pre> <p>Parameters: - <code>texts</code>: List of text strings</p> <p>Returns: - List of embedding vectors</p>"},{"location":"api/embeddings/#embed_query","title":"embed_query","text":"<pre><code>def embed_query(self, text: str) -&gt; List[float]:\n    \"\"\"Generate embedding for a single query text.\"\"\"\n</code></pre> <p>Parameters: - <code>text</code>: Query text</p> <p>Returns: - Embedding vector</p>"},{"location":"api/embeddings/#usage-example","title":"Usage Example","text":"<pre><code># Initialize embeddings\nembeddings = NomicEmbeddings()\n\n# Embed documents\ndocs = [\"First document\", \"Second document\"]\ndoc_embeddings = embeddings.embed_documents(docs)\n\n# Embed query\nquery = \"Sample query\"\nquery_embedding = embeddings.embed_query(query)\n</code></pre>"},{"location":"api/embeddings/#configuration","title":"Configuration","text":"<p>Configure embeddings with:</p> <ul> <li>Model selection</li> <li>Batch size</li> <li>Normalization</li> <li>Caching options</li> </ul>"},{"location":"api/embeddings/#performance","title":"Performance","text":"<p>Optimization options:</p> <ul> <li>Batch processing</li> <li>GPU acceleration</li> <li>Caching</li> <li>Dimensionality</li> </ul>"},{"location":"api/embeddings/#best-practices","title":"Best Practices","text":"<ol> <li>Text Preparation</li> <li>Clean input text</li> <li>Handle special characters</li> <li> <p>Normalize length</p> </li> <li> <p>Resource Management</p> </li> <li>Batch similar lengths</li> <li>Monitor memory usage</li> <li> <p>Cache frequent queries</p> </li> <li> <p>Quality Control</p> </li> <li>Validate embeddings</li> <li>Check dimensions</li> <li>Monitor similarity scores ``` </li> </ol>"},{"location":"api/llm/","title":"LLM Manager API","text":"<p>This page documents the Language Model management components.</p>"},{"location":"api/llm/#llmmanager","title":"LLMManager","text":"<pre><code>class LLMManager:\n    \"\"\"Manages Ollama language model interactions.\"\"\"\n\n    def __init__(self, model_name: str = \"llama2\"):\n        \"\"\"Initialize LLM manager with model name.\"\"\"\n</code></pre>"},{"location":"api/llm/#methods","title":"Methods","text":""},{"location":"api/llm/#list_models","title":"list_models","text":"<pre><code>def list_models() -&gt; List[str]:\n    \"\"\"List available Ollama models.\"\"\"\n</code></pre> <p>Returns: - List of model names</p>"},{"location":"api/llm/#get_model","title":"get_model","text":"<pre><code>def get_model(self, model_name: str) -&gt; LLM:\n    \"\"\"Get an instance of the specified model.\"\"\"\n</code></pre> <p>Parameters: - <code>model_name</code>: Name of the Ollama model</p> <p>Returns: - LLM instance</p>"},{"location":"api/llm/#generate","title":"generate","text":"<pre><code>def generate(self, prompt: str, **kwargs) -&gt; str:\n    \"\"\"Generate text using the current model.\"\"\"\n</code></pre> <p>Parameters: - <code>prompt</code>: Input text - <code>**kwargs</code>: Additional generation parameters</p> <p>Returns: - Generated text</p>"},{"location":"api/llm/#usage-example","title":"Usage Example","text":"<pre><code># Initialize manager\nmanager = LLMManager(model_name=\"llama2\")\n\n# List available models\nmodels = manager.list_models()\n\n# Generate text\nresponse = manager.generate(\n    prompt=\"Explain RAG in simple terms\",\n    temperature=0.7,\n    max_tokens=500\n)\n</code></pre>"},{"location":"api/llm/#model-parameters","title":"Model Parameters","text":"<p>Configure model behavior with:</p> <ul> <li><code>temperature</code>: Creativity (0.0-1.0)</li> <li><code>max_tokens</code>: Response length</li> <li><code>top_p</code>: Nucleus sampling</li> <li><code>frequency_penalty</code>: Repetition control</li> </ul>"},{"location":"api/llm/#error-handling","title":"Error Handling","text":"<p>The manager handles:</p> <ul> <li>Model loading errors</li> <li>Generation timeouts</li> <li>Resource constraints</li> <li>API communication issues</li> </ul>"},{"location":"api/llm/#best-practices","title":"Best Practices","text":"<ol> <li>Model Selection</li> <li>Match model to task</li> <li>Consider resource usage</li> <li> <p>Test performance</p> </li> <li> <p>Parameter Tuning</p> </li> <li>Adjust temperature</li> <li>Control response length</li> <li>Balance quality/speed ``` </li> </ol>"},{"location":"api/rag/","title":"RAG Pipeline API","text":"<p>This page documents the RAG (Retrieval Augmented Generation) pipeline components.</p>"},{"location":"api/rag/#ragpipeline","title":"RAGPipeline","text":"<pre><code>class RAGPipeline:\n    \"\"\"Manages the RAG pipeline for document question-answering.\"\"\"\n\n    def __init__(self, model_name: str, embeddings: Embeddings):\n        \"\"\"Initialize RAG pipeline with model and embeddings.\"\"\"\n</code></pre>"},{"location":"api/rag/#methods","title":"Methods","text":""},{"location":"api/rag/#create_vector_store","title":"create_vector_store","text":"<pre><code>def create_vector_store(self, documents: List[Document]) -&gt; VectorStore:\n    \"\"\"Create a vector store from documents.\"\"\"\n</code></pre> <p>Parameters: - <code>documents</code>: List of processed documents</p> <p>Returns: - Initialized vector store</p>"},{"location":"api/rag/#get_relevant_documents","title":"get_relevant_documents","text":"<pre><code>def get_relevant_documents(self, query: str) -&gt; List[Document]:\n    \"\"\"Retrieve relevant documents for a query.\"\"\"\n</code></pre> <p>Parameters: - <code>query</code>: User question - <code>k</code>: Number of documents to retrieve (default: 4)</p> <p>Returns: - List of relevant documents</p>"},{"location":"api/rag/#generate_response","title":"generate_response","text":"<pre><code>def generate_response(self, query: str, context: List[Document]) -&gt; str:\n    \"\"\"Generate response using LLM and context.\"\"\"\n</code></pre> <p>Parameters: - <code>query</code>: User question - <code>context</code>: Retrieved documents</p> <p>Returns: - Generated response</p>"},{"location":"api/rag/#usage-example","title":"Usage Example","text":"<pre><code># Initialize pipeline\npipeline = RAGPipeline(\n    model_name=\"llama2\",\n    embeddings=NonicEmbeddings()\n)\n\n# Process query\ndocs = pipeline.get_relevant_documents(\"What is RAG?\")\nresponse = pipeline.generate_response(\n    query=\"What is RAG?\",\n    context=docs\n)\n</code></pre>"},{"location":"api/rag/#configuration","title":"Configuration","text":"<p>The pipeline can be configured with:</p> <ul> <li>Model selection</li> <li>Embedding type</li> <li>Retrieval parameters</li> <li>Response templates</li> </ul>"},{"location":"api/rag/#performance-tuning","title":"Performance Tuning","text":"<p>Optimize the pipeline by adjusting:</p> <ul> <li>Number of retrieved documents</li> <li>Context window size</li> <li>Temperature setting</li> <li>Response length </li> </ul>"},{"location":"api/rest-api/","title":"REST API Reference","text":"<p>The FastAPI backend provides a REST API for PDF management and RAG queries.</p> <p>Base URL: <code>http://localhost:8001</code></p>"},{"location":"api/rest-api/#interactive-documentation","title":"Interactive Documentation","text":"<p>FastAPI provides automatic interactive API docs:</p> <ul> <li>Swagger UI: http://localhost:8001/docs</li> <li>ReDoc: http://localhost:8001/redoc</li> </ul>"},{"location":"api/rest-api/#endpoints-overview","title":"Endpoints Overview","text":"Method Endpoint Description GET <code>/health</code> Health check GET <code>/api/v1/models</code> List available models GET <code>/api/v1/pdfs</code> List uploaded PDFs POST <code>/api/v1/pdfs/upload</code> Upload a PDF DELETE <code>/api/v1/pdfs/{pdf_id}</code> Delete a PDF POST <code>/api/v1/query</code> RAG query GET <code>/api/v1/sessions/{session_id}/messages</code> Get chat history"},{"location":"api/rest-api/#health-check","title":"Health Check","text":""},{"location":"api/rest-api/#get-health","title":"<code>GET /health</code>","text":"<p>Check if the API is running and Ollama is accessible.</p> <p>Response:</p> <pre><code>{\n  \"status\": \"healthy\",\n  \"ollama_status\": \"connected\",\n  \"models_available\": 3\n}\n</code></pre>"},{"location":"api/rest-api/#models","title":"Models","text":""},{"location":"api/rest-api/#get-apiv1models","title":"<code>GET /api/v1/models</code>","text":"<p>List available Ollama chat models.</p> <p>Response:</p> <pre><code>[\n  {\n    \"name\": \"qwen3:8b\",\n    \"size\": 4932501234,\n    \"modified_at\": \"2024-12-19T10:00:00Z\",\n    \"is_chat_model\": true\n  },\n  {\n    \"name\": \"llama3.2\",\n    \"size\": 2019234567,\n    \"modified_at\": \"2024-12-18T15:00:00Z\",\n    \"is_chat_model\": true\n  }\n]\n</code></pre> <p>Notes: - Only returns chat-capable models (excludes embedding models) - Size is in bytes - Filters out models without chat templates</p>"},{"location":"api/rest-api/#pdf-management","title":"PDF Management","text":""},{"location":"api/rest-api/#get-apiv1pdfs","title":"<code>GET /api/v1/pdfs</code>","text":"<p>List all uploaded PDFs.</p> <p>Response:</p> <pre><code>[\n  {\n    \"pdf_id\": \"pdf_4122871031772577363\",\n    \"name\": \"Security_Guide.pdf\",\n    \"collection_name\": \"pdf_4122871031772577363\",\n    \"upload_timestamp\": \"2024-12-19T18:00:00Z\",\n    \"doc_count\": 45,\n    \"page_count\": 12,\n    \"is_sample\": false\n  }\n]\n</code></pre> Field Type Description pdf_id string Unique identifier name string Original filename collection_name string ChromaDB collection name upload_timestamp datetime When uploaded doc_count integer Number of chunks page_count integer Original page count is_sample boolean Is a sample PDF"},{"location":"api/rest-api/#post-apiv1pdfsupload","title":"<code>POST /api/v1/pdfs/upload</code>","text":"<p>Upload and process a PDF file.</p> <p>Request:</p> <pre><code>curl -X POST \"http://localhost:8001/api/v1/pdfs/upload\" \\\n  -H \"Content-Type: multipart/form-data\" \\\n  -F \"file=@document.pdf\"\n</code></pre> <p>Response:</p> <pre><code>{\n  \"pdf_id\": \"pdf_4122871031772577363\",\n  \"name\": \"document.pdf\",\n  \"collection_name\": \"pdf_4122871031772577363\",\n  \"doc_count\": 23,\n  \"page_count\": 8,\n  \"upload_timestamp\": \"2024-12-19T18:30:00Z\"\n}\n</code></pre> <p>Errors:</p> Status Description 400 Not a PDF file 500 Processing failed <p>Processing Steps: 1. Save file to disk 2. Extract text with UnstructuredPDFLoader 3. Split into chunks (7500 chars, 100 overlap) 4. Generate embeddings (nomic-embed-text) 5. Store in ChromaDB 6. Save metadata to SQLite</p>"},{"location":"api/rest-api/#delete-apiv1pdfspdf_id","title":"<code>DELETE /api/v1/pdfs/{pdf_id}</code>","text":"<p>Delete a PDF and its vectors.</p> <p>Request:</p> <pre><code>curl -X DELETE \"http://localhost:8001/api/v1/pdfs/pdf_4122871031772577363\"\n</code></pre> <p>Response:</p> <pre><code>{\n  \"message\": \"PDF deleted successfully\"\n}\n</code></pre> <p>Errors:</p> Status Description 404 PDF not found <p>Deletes: - PDF file from disk - Vector collection from ChromaDB - Metadata from SQLite</p>"},{"location":"api/rest-api/#rag-query","title":"RAG Query","text":""},{"location":"api/rest-api/#post-apiv1query","title":"<code>POST /api/v1/query</code>","text":"<p>Query documents using RAG.</p> <p>Request:</p> <pre><code>{\n  \"question\": \"What are the security requirements?\",\n  \"model\": \"qwen3:8b\",\n  \"pdf_ids\": [\"pdf_123\", \"pdf_456\"],\n  \"session_id\": \"optional-session-id\"\n}\n</code></pre> Field Type Required Description question string Yes User's question model string Yes Ollama model name pdf_ids array No PDFs to search (null = all) session_id string No Chat session ID <p>Response:</p> <pre><code>{\n  \"answer\": \"Based on the documents, the security requirements include...\",\n  \"sources\": [\n    {\n      \"pdf_name\": \"Security_Guide.pdf\",\n      \"pdf_id\": \"pdf_123\",\n      \"chunk_index\": 3\n    },\n    {\n      \"pdf_name\": \"Security_Guide.pdf\",\n      \"pdf_id\": \"pdf_123\",\n      \"chunk_index\": 7\n    }\n  ],\n  \"metadata\": {\n    \"model_used\": \"qwen3:8b\",\n    \"chunks_retrieved\": 10,\n    \"pdfs_queried\": 2,\n    \"reasoning_steps\": [\n      \"\ud83d\udcda Searching across 2 PDF(s): Security_Guide.pdf, Policy.pdf\",\n      \"\ud83e\udd16 Using model: qwen3:8b\",\n      \"\ud83d\udd0d Generating alternative search queries...\",\n      \"\ud83d\udcc4 Retrieving from: Security_Guide.pdf\",\n      \"\u2705 Found 5 relevant chunks in Security_Guide.pdf\",\n      \"\ud83d\udcc4 Retrieving from: Policy.pdf\",\n      \"\u2705 Found 3 relevant chunks in Policy.pdf\",\n      \"\ud83d\udcca Total chunks retrieved: 8\",\n      \"\ud83d\udd17 Using top 8 chunks for context\",\n      \"\ud83d\udcad Generating answer with source citations...\",\n      \"\ud83e\udde0 Using thinking-enabled model for deeper reasoning...\",\n      \"\u2728 Answer generated successfully!\"\n    ]\n  },\n  \"session_id\": \"e4b444b3-7adb-4da3-aefb-e2b745c7719c\",\n  \"message_id\": 42\n}\n</code></pre> Field Type Description answer string Generated response sources array Source chunks used metadata object Processing details session_id string Chat session ID message_id integer Database message ID <p>Errors:</p> Status Description 404 Model not found 500 Query failed"},{"location":"api/rest-api/#chat-history","title":"Chat History","text":""},{"location":"api/rest-api/#get-apiv1sessionssession_idmessages","title":"<code>GET /api/v1/sessions/{session_id}/messages</code>","text":"<p>Get chat history for a session.</p> <p>Request:</p> <pre><code>curl \"http://localhost:8001/api/v1/sessions/e4b444b3-7adb/messages\"\n</code></pre> <p>Response:</p> <pre><code>[\n  {\n    \"message_id\": 41,\n    \"role\": \"user\",\n    \"content\": \"What are the security requirements?\",\n    \"sources\": null,\n    \"timestamp\": \"2024-12-19T18:30:00Z\"\n  },\n  {\n    \"message_id\": 42,\n    \"role\": \"assistant\",\n    \"content\": \"Based on the documents...\",\n    \"sources\": [\n      {\"pdf_name\": \"Security_Guide.pdf\", \"chunk_index\": 3}\n    ],\n    \"timestamp\": \"2024-12-19T18:30:15Z\"\n  }\n]\n</code></pre>"},{"location":"api/rest-api/#error-responses","title":"Error Responses","text":"<p>All errors follow this format:</p> <pre><code>{\n  \"detail\": \"Error message here\"\n}\n</code></pre> Status Meaning 400 Bad request (invalid input) 404 Resource not found 500 Internal server error"},{"location":"api/rest-api/#usage-examples","title":"Usage Examples","text":""},{"location":"api/rest-api/#python","title":"Python","text":"<pre><code>import requests\n\n# Upload PDF\nwith open(\"document.pdf\", \"rb\") as f:\n    response = requests.post(\n        \"http://localhost:8001/api/v1/pdfs/upload\",\n        files={\"file\": f}\n    )\npdf_id = response.json()[\"pdf_id\"]\n\n# Query\nresponse = requests.post(\n    \"http://localhost:8001/api/v1/query\",\n    json={\n        \"question\": \"What is this about?\",\n        \"model\": \"llama3.2\",\n        \"pdf_ids\": [pdf_id]\n    }\n)\nprint(response.json()[\"answer\"])\n</code></pre>"},{"location":"api/rest-api/#javascript","title":"JavaScript","text":"<pre><code>// Upload PDF\nconst formData = new FormData();\nformData.append('file', pdfFile);\n\nconst uploadRes = await fetch('http://localhost:8001/api/v1/pdfs/upload', {\n  method: 'POST',\n  body: formData\n});\nconst { pdf_id } = await uploadRes.json();\n\n// Query\nconst queryRes = await fetch('http://localhost:8001/api/v1/query', {\n  method: 'POST',\n  headers: { 'Content-Type': 'application/json' },\n  body: JSON.stringify({\n    question: 'What is this about?',\n    model: 'llama3.2',\n    pdf_ids: [pdf_id]\n  })\n});\nconst { answer } = await queryRes.json();\n</code></pre>"},{"location":"api/rest-api/#curl","title":"cURL","text":"<pre><code># Upload\ncurl -X POST \"http://localhost:8001/api/v1/pdfs/upload\" \\\n  -F \"file=@document.pdf\"\n\n# Query\ncurl -X POST \"http://localhost:8001/api/v1/query\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"question\":\"What is this about?\",\"model\":\"llama3.2\"}'\n</code></pre>"},{"location":"development/changelog/","title":"Changelog","text":"<p>All notable changes to Ollama PDF RAG are documented here.</p>"},{"location":"development/changelog/#v300-2025-12-19","title":"[v3.0.0] - 2025-12-19","text":""},{"location":"development/changelog/#major-features","title":"\ud83d\ude80 Major Features","text":""},{"location":"development/changelog/#nextjs-frontend","title":"Next.js Frontend","text":"<ul> <li>Modern Chat UI - Beautiful, responsive chat interface built with Next.js 16 and React 19</li> <li>Real-time Streaming - Live message streaming with Vercel AI SDK</li> <li>Chat Persistence - SQLite database for saving all conversations</li> <li>PDF Selection - Checkbox-based PDF selection before chatting</li> <li>Question Classification - Auto-detects if questions need document context</li> <li>Model Selector - Switch between Ollama models on the fly</li> <li>Theme Support - Dark/light mode toggle</li> </ul>"},{"location":"development/changelog/#fastapi-backend","title":"FastAPI Backend","text":"<ul> <li>REST API - Production-ready API with OpenAPI docs</li> <li>PDF Management - Upload, list, delete PDF endpoints</li> <li>RAG Query - Multi-PDF query with source attribution</li> <li>Session Management - Chat history per session</li> <li>Health Monitoring - Ollama connection status</li> </ul>"},{"location":"development/changelog/#enhanced-rag","title":"Enhanced RAG","text":"<ul> <li>Multi-Query Retrieval - Generates alternative queries for better recall</li> <li>Thinking Models - Support for qwen3, deepseek-r1 chain-of-thought</li> <li>PDF Filtering - Query specific PDFs, not all</li> <li>Source Citations - Every answer includes chunk sources</li> </ul>"},{"location":"development/changelog/#documentation","title":"\ud83d\udcd6 Documentation","text":"<ul> <li>MkDocs Site - Comprehensive documentation with Material theme</li> <li>API Reference - Full REST API documentation</li> <li>Architecture Diagrams - Visual pipeline explanations</li> <li>Screenshots - UI screenshots in docs</li> </ul>"},{"location":"development/changelog/#infrastructure","title":"\ud83d\udd27 Infrastructure","text":"<ul> <li>GitHub Actions - Updated CI for Python 3.10-3.12</li> <li>Security Updates - Patched Dependabot vulnerabilities</li> <li>Improved Tests - Mocked tests without Ollama dependency</li> </ul>"},{"location":"development/changelog/#breaking-changes","title":"\ud83d\udca5 Breaking Changes","text":"<ul> <li>Python 3.9 no longer supported (requires 3.10+)</li> <li>New FastAPI backend required on port 8001</li> <li>Database schema changes for chat persistence</li> </ul>"},{"location":"development/changelog/#v210-2024-01-07","title":"[v2.1.0] - 2024-01-07","text":""},{"location":"development/changelog/#added","title":"Added","text":"<ul> <li>Comprehensive test suite with pytest</li> <li>GitHub Actions CI pipeline</li> <li>Pre-commit hooks for code quality</li> <li>Test coverage reporting</li> <li>Project restructuring with clean architecture</li> <li>New directory structure for better organization</li> <li>Sample PDFs in dedicated folder</li> </ul>"},{"location":"development/changelog/#changed","title":"Changed","text":"<ul> <li>Moved all source code to src/ directory</li> <li>Updated dependencies to latest compatible versions</li> <li>Improved README with testing documentation</li> <li>Added test status badge</li> <li>Reorganized PDF storage structure</li> </ul>"},{"location":"development/changelog/#fixed","title":"Fixed","text":"<ul> <li>Dependency conflicts with pydantic</li> <li>ONNX runtime compatibility issues</li> <li>Test coverage configuration</li> </ul>"},{"location":"development/changelog/#v20-2023-11-05","title":"[v2.0] - 2023-11-05","text":"<ul> <li>Major version release</li> <li>Improved RAG implementation</li> <li>Enhanced PDF processing</li> </ul>"},{"location":"development/changelog/#v10-2023-07-08","title":"[v1.0] - 2023-07-08","text":"<ul> <li>Initial release</li> <li>Basic RAG functionality</li> <li>PDF processing capabilities</li> <li>Streamlit interface</li> <li>Jupyter notebook for experimentation</li> </ul>"},{"location":"development/changelog/#version-history","title":"Version History","text":"Version Date Highlights v3.0.0 2025-12-19 Next.js UI, FastAPI, Enhanced RAG v2.1.0 2024-01-07 Test suite, CI/CD, restructuring v2.0 2023-11-05 Improved RAG, enhanced processing v1.0 2023-07-08 Initial release"},{"location":"development/changelog/#upgrade-guide","title":"Upgrade Guide","text":""},{"location":"development/changelog/#from-v2x-to-v300","title":"From v2.x to v3.0.0","text":"<ol> <li> <p>Python Version: Upgrade to Python 3.10+    <pre><code>python --version  # Should be 3.10+\n</code></pre></p> </li> <li> <p>Install New Dependencies:    <pre><code>pip install -r requirements.txt\n</code></pre></p> </li> <li> <p>Setup Next.js Frontend:    <pre><code>cd web-ui\npnpm install\n</code></pre></p> </li> <li> <p>Start Services:    <pre><code># Option 1: Use start script\n./start_all.sh\n\n# Option 2: Manual\npython run_api.py &amp;  # Terminal 1\ncd web-ui &amp;&amp; pnpm dev  # Terminal 2\n</code></pre></p> </li> <li> <p>Access New UI: Open http://localhost:3000</p> </li> </ol>"},{"location":"development/changelog/#migration-notes","title":"Migration Notes","text":""},{"location":"development/changelog/#database-changes","title":"Database Changes","text":"<p>The Next.js UI uses a separate SQLite database for chat history: - Location: <code>web-ui/data/chat.db</code> - Contains: chats, messages, users</p> <p>The FastAPI backend uses: - Location: <code>data/api.db</code> - Contains: PDF metadata, chat sessions</p>"},{"location":"development/changelog/#breaking-changes-in-v300","title":"Breaking Changes in v3.0.0","text":"<ul> <li>Python 3.9 is no longer supported</li> <li>Streamlit app now runs on port 8501</li> <li>New FastAPI backend required on port 8001</li> <li>New dependency: Node.js 18+ and pnpm</li> </ul>"},{"location":"development/changelog/#roadmap","title":"Roadmap","text":""},{"location":"development/changelog/#upcoming-features","title":"Upcoming Features","text":"<ul> <li> Image extraction from PDFs</li> <li> OCR support for scanned documents  </li> <li> Multi-user authentication</li> <li> Document comparison mode</li> <li> Export chat history</li> <li> API key management</li> <li> Custom embedding models</li> <li> Batch PDF processing</li> </ul>"},{"location":"development/contributing/","title":"Contributing Guide","text":"<p>Thank you for considering contributing to Ollama PDF RAG! This document provides guidelines and instructions for contributing.</p>"},{"location":"development/contributing/#code-of-conduct","title":"Code of Conduct","text":"<p>This project follows a Code of Conduct that all contributors are expected to adhere to. Please read CODE_OF_CONDUCT.md before contributing.</p>"},{"location":"development/contributing/#how-to-contribute","title":"How to Contribute","text":""},{"location":"development/contributing/#setting-up-development-environment","title":"Setting Up Development Environment","text":"<ol> <li>Fork the repository</li> <li> <p>Clone your fork:    <pre><code>git clone https://github.com/YOUR_USERNAME/ollama_pdf_rag.git\ncd ollama_pdf_rag\n</code></pre></p> </li> <li> <p>Create a virtual environment:    <pre><code>python -m venv venv\nsource venv/bin/activate  # On Windows: .\\venv\\Scripts\\activate\n</code></pre></p> </li> <li> <p>Install development dependencies:    <pre><code>pip install -r requirements.txt\npip install pre-commit pytest pytest-cov\n</code></pre></p> </li> <li> <p>Set up pre-commit hooks:    <pre><code>pre-commit install\n</code></pre></p> </li> </ol>"},{"location":"development/contributing/#development-workflow","title":"Development Workflow","text":"<ol> <li> <p>Create a new branch:    <pre><code>git checkout -b feature/your-feature-name\n</code></pre></p> </li> <li> <p>Make your changes</p> </li> <li> <p>Run tests:    <pre><code>pytest\n</code></pre></p> </li> <li> <p>Commit your changes:    <pre><code>git add .\ngit commit -m \"feat: Add new feature\"\n</code></pre></p> </li> <li> <p>Push to your fork:    <pre><code>git push origin feature/your-feature-name\n</code></pre></p> </li> <li> <p>Create a Pull Request</p> </li> </ol>"},{"location":"development/contributing/#commit-message-guidelines","title":"Commit Message Guidelines","text":"<p>We follow conventional commits. Format: <pre><code>type(scope): description\n\n[optional body]\n\n[optional footer]\n</code></pre></p> <p>Types: - feat: New feature - fix: Bug fix - docs: Documentation - style: Formatting - refactor: Code restructuring - test: Adding tests - chore: Maintenance</p>"},{"location":"development/contributing/#running-tests","title":"Running Tests","text":"<pre><code># Run all tests\npytest\n\n# Run with coverage\npytest --cov=src\n\n# Run specific test file\npytest tests/test_document.py\n</code></pre>"},{"location":"development/contributing/#documentation","title":"Documentation","text":"<ul> <li>Update documentation for any new features</li> <li>Add docstrings to new functions/classes</li> <li>Update README.md if needed</li> </ul>"},{"location":"development/contributing/#pull-request-process","title":"Pull Request Process","text":"<ol> <li>Update documentation</li> <li>Add tests for new features</li> <li>Ensure all tests pass</li> <li>Update CHANGELOG.md</li> <li>Request review from maintainers</li> </ol>"},{"location":"development/contributing/#code-style","title":"Code Style","text":"<ul> <li>Follow PEP 8</li> <li>Use type hints</li> <li>Add docstrings (Google style)</li> <li>Keep functions focused and small</li> </ul>"},{"location":"development/contributing/#getting-help","title":"Getting Help","text":"<ul> <li>Open an issue for bugs</li> <li>Discuss major changes in issues first</li> <li>Join our community discussions</li> </ul>"},{"location":"development/contributing/#release-process","title":"Release Process","text":"<ol> <li>Update version in relevant files</li> <li>Update CHANGELOG.md</li> <li>Create a new release on GitHub</li> <li>Tag the release</li> </ol>"},{"location":"development/contributing/#license","title":"License","text":"<p>By contributing, you agree that your contributions will be licensed under the MIT License. </p>"},{"location":"development/testing/","title":"Testing Guide","text":"<p>This guide covers testing practices and procedures for Ollama PDF RAG.</p>"},{"location":"development/testing/#overview","title":"Overview","text":"<p>We use pytest for testing and maintain high test coverage to ensure code quality. Tests are organized by component and include unit tests, integration tests, and end-to-end tests.</p>"},{"location":"development/testing/#test-structure","title":"Test Structure","text":"<pre><code>tests/\n\u251c\u2500\u2500 __init__.py\n\u251c\u2500\u2500 test_document.py    # Document processing tests\n\u251c\u2500\u2500 test_models.py      # Model extraction tests\n\u2514\u2500\u2500 test_rag.py        # RAG pipeline tests\n</code></pre>"},{"location":"development/testing/#running-tests","title":"Running Tests","text":""},{"location":"development/testing/#basic-test-execution","title":"Basic Test Execution","text":"<pre><code># Run all tests\npytest\n\n# Run tests with output\npytest -v\n\n# Run specific test file\npytest tests/test_document.py\n\n# Run specific test function\npytest tests/test_document.py::test_split_documents\n</code></pre>"},{"location":"development/testing/#coverage-reports","title":"Coverage Reports","text":"<pre><code># Generate coverage report\npytest --cov=src\n\n# Generate detailed coverage report\npytest --cov=src --cov-report=term-missing\n\n# Generate HTML coverage report\npytest --cov=src --cov-report=html\n</code></pre>"},{"location":"development/testing/#writing-tests","title":"Writing Tests","text":""},{"location":"development/testing/#test-file-structure","title":"Test File Structure","text":"<pre><code>\"\"\"Test module docstring.\"\"\"\nimport pytest\nfrom unittest.mock import Mock, patch\n\ndef test_function_name():\n    \"\"\"Test docstring explaining what is being tested.\"\"\"\n    # Arrange\n    input_data = ...\n\n    # Act\n    result = function_to_test(input_data)\n\n    # Assert\n    assert result == expected_output\n</code></pre>"},{"location":"development/testing/#using-fixtures","title":"Using Fixtures","text":"<pre><code>@pytest.fixture\ndef processor():\n    \"\"\"Create a DocumentProcessor instance.\"\"\"\n    return DocumentProcessor()\n\ndef test_with_fixture(processor):\n    \"\"\"Test using the fixture.\"\"\"\n    result = processor.process_document()\n    assert result is not None\n</code></pre>"},{"location":"development/testing/#mocking","title":"Mocking","text":"<pre><code>@patch('module.class.method')\ndef test_with_mock(mock_method):\n    \"\"\"Test using a mock.\"\"\"\n    mock_method.return_value = expected_value\n    result = function_that_uses_method()\n    assert result == expected_value\n</code></pre>"},{"location":"development/testing/#test-categories","title":"Test Categories","text":""},{"location":"development/testing/#unit-tests","title":"Unit Tests","text":"<ul> <li>Test individual functions/methods</li> <li>Mock dependencies</li> <li>Fast execution</li> <li>High coverage</li> </ul>"},{"location":"development/testing/#integration-tests","title":"Integration Tests","text":"<ul> <li>Test component interactions</li> <li>Minimal mocking</li> <li>Focus on integration points</li> </ul>"},{"location":"development/testing/#end-to-end-tests","title":"End-to-End Tests","text":"<ul> <li>Test complete workflows</li> <li>No mocking</li> <li>Slower execution</li> <li>Critical path coverage</li> </ul>"},{"location":"development/testing/#best-practices","title":"Best Practices","text":"<ol> <li>Test Organization</li> <li>One test file per module</li> <li>Clear test names</li> <li> <p>Descriptive docstrings</p> </li> <li> <p>Test Independence</p> </li> <li>Tests should not depend on each other</li> <li>Clean up after tests</li> <li> <p>Use fixtures for setup/teardown</p> </li> <li> <p>Test Coverage</p> </li> <li>Aim for high coverage</li> <li>Focus on critical paths</li> <li> <p>Test edge cases</p> </li> <li> <p>Assertions</p> </li> <li>One assertion per test when possible</li> <li>Clear failure messages</li> <li>Test both positive and negative cases</li> </ol>"},{"location":"development/testing/#continuous-integration","title":"Continuous Integration","text":"<p>Tests run automatically on: - Every push to main - Pull requests - Release tags</p> <p>GitHub Actions configuration: <pre><code>name: Python Tests\non: [push, pull_request]\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - name: Run tests\n        run: pytest\n</code></pre></p>"},{"location":"development/testing/#common-issues","title":"Common Issues","text":""},{"location":"development/testing/#test-performance","title":"Test Performance","text":"<ul> <li>Use appropriate fixtures</li> <li>Mock expensive operations</li> <li>Parallelize test execution</li> </ul>"},{"location":"development/testing/#flaky-tests","title":"Flaky Tests","text":"<ul> <li>Avoid time-dependent tests</li> <li>Use stable test data</li> <li>Handle async operations properly</li> </ul>"},{"location":"development/testing/#coverage-gaps","title":"Coverage Gaps","text":"<ul> <li>Identify uncovered code</li> <li>Add missing test cases</li> <li>Focus on critical functionality</li> </ul>"},{"location":"development/testing/#resources","title":"Resources","text":"<ul> <li>pytest Documentation</li> <li>Coverage.py Documentation</li> <li>Python Testing Best Practices </li> </ul>"},{"location":"getting-started/installation/","title":"Installation Guide","text":"<p>This guide walks you through setting up Ollama PDF RAG on your system.</p>"},{"location":"getting-started/installation/#prerequisites","title":"Prerequisites","text":"<p>Before installing, ensure you have:</p> Requirement Version Notes Python 3.10+ Required for LangChain 1.0 Node.js 18+ For Next.js frontend pnpm 9+ Package manager for Node.js Ollama Latest Local LLM server Git Any For cloning the repo"},{"location":"getting-started/installation/#step-1-install-ollama","title":"Step 1: Install Ollama","text":""},{"location":"getting-started/installation/#macos-linux","title":"macOS / Linux","text":"<pre><code>curl -fsSL https://ollama.com/install.sh | sh\n</code></pre>"},{"location":"getting-started/installation/#windows","title":"Windows","text":"<p>Download from ollama.com/download</p>"},{"location":"getting-started/installation/#verify-installation","title":"Verify Installation","text":"<pre><code>ollama --version\n</code></pre>"},{"location":"getting-started/installation/#step-2-pull-required-models","title":"Step 2: Pull Required Models","text":"<pre><code># Chat model (choose one or more)\nollama pull llama3.2          # Recommended - fast &amp; capable\nollama pull qwen3:8b          # Great for thinking/reasoning\nollama pull mistral           # Alternative option\n\n# Embedding model (required)\nollama pull nomic-embed-text\n</code></pre> <p>Model Selection</p> <ul> <li>qwen3:8b and deepseek-r1 support \"thinking mode\" for chain-of-thought reasoning</li> <li>llama3.2 is fastest for general use</li> <li>You can pull multiple models and switch between them in the UI</li> </ul>"},{"location":"getting-started/installation/#step-3-clone-the-repository","title":"Step 3: Clone the Repository","text":"<pre><code>git clone https://github.com/tonykipkemboi/ollama_pdf_rag.git\ncd ollama_pdf_rag\n</code></pre>"},{"location":"getting-started/installation/#step-4-python-environment-setup","title":"Step 4: Python Environment Setup","text":""},{"location":"getting-started/installation/#using-venv-recommended","title":"Using venv (Recommended)","text":"<pre><code># Create virtual environment\npython -m venv .venv\n\n# Activate it\n# macOS/Linux:\nsource .venv/bin/activate\n\n# Windows:\n.venv\\Scripts\\activate\n\n# Install dependencies\npip install -r requirements.txt\n</code></pre>"},{"location":"getting-started/installation/#using-uv-faster-alternative","title":"Using uv (Faster Alternative)","text":"<pre><code># Install uv if you don't have it\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n\n# Create environment and install\nuv venv\nsource .venv/bin/activate\nuv pip install -r requirements.txt\n</code></pre>"},{"location":"getting-started/installation/#step-5-nextjs-frontend-setup","title":"Step 5: Next.js Frontend Setup","text":"<pre><code>cd web-ui\n\n# Install dependencies\npnpm install\n\n# Return to project root\ncd ..\n</code></pre>"},{"location":"getting-started/installation/#step-6-verify-installation","title":"Step 6: Verify Installation","text":""},{"location":"getting-started/installation/#start-the-backend","title":"Start the Backend","text":"<pre><code>python run_api.py\n</code></pre> <p>You should see:</p> <pre><code>INFO:     Uvicorn running on http://0.0.0.0:8001\nINFO:     Application startup complete.\n</code></pre>"},{"location":"getting-started/installation/#start-the-frontend-new-terminal","title":"Start the Frontend (New Terminal)","text":"<pre><code>cd web-ui\npnpm dev\n</code></pre> <p>You should see:</p> <pre><code>\u25b2 Next.js 16.0.10\n- Local:        http://localhost:3000\n</code></pre>"},{"location":"getting-started/installation/#test-the-app","title":"Test the App","text":"<ol> <li>Open http://localhost:3000</li> <li>You should see the PDF Chat interface</li> <li>Upload a PDF using the \ud83d\udcce button</li> <li>Select it with the checkbox</li> <li>Ask a question!</li> </ol>"},{"location":"getting-started/installation/#directory-structure","title":"Directory Structure","text":"<p>After installation, your directory should look like:</p> <pre><code>ollama_pdf_rag/\n\u251c\u2500\u2500 .venv/                 # Python virtual environment\n\u251c\u2500\u2500 data/\n\u2502   \u251c\u2500\u2500 pdfs/             # Uploaded PDFs\n\u2502   \u2502   \u251c\u2500\u2500 sample/       # Sample PDFs\n\u2502   \u2502   \u2514\u2500\u2500 uploads/      # User uploads\n\u2502   \u251c\u2500\u2500 vectors/          # ChromaDB vector storage\n\u2502   \u2514\u2500\u2500 api.db            # SQLite metadata\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 api/              # FastAPI backend\n\u2502   \u251c\u2500\u2500 app/              # Streamlit app\n\u2502   \u2514\u2500\u2500 core/             # Core RAG logic\n\u251c\u2500\u2500 web-ui/               # Next.js frontend\n\u2502   \u251c\u2500\u2500 app/              # Next.js app router\n\u2502   \u251c\u2500\u2500 components/       # React components\n\u2502   \u2514\u2500\u2500 data/\n\u2502       \u2514\u2500\u2500 chat.db       # Chat history\n\u251c\u2500\u2500 requirements.txt      # Python dependencies\n\u2514\u2500\u2500 run_api.py           # Start FastAPI server\n</code></pre>"},{"location":"getting-started/installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/installation/#onnx-dll-error-windows","title":"ONNX DLL Error (Windows)","text":"<pre><code>DLL load failed while importing onnx_copy2py_export\n</code></pre> <p>Solution:</p> <ol> <li>Install Microsoft Visual C++ Redistributable</li> <li>Restart your computer</li> <li>Or try:    <pre><code>pip uninstall onnxruntime onnxruntime-gpu\npip install onnxruntime\n</code></pre></li> </ol>"},{"location":"getting-started/installation/#port-already-in-use","title":"Port Already in Use","text":"<pre><code>Address already in use: 8001\n</code></pre> <p>Solution:</p> <pre><code># Find process using the port\nlsof -i :8001\n\n# Kill it\nkill -9 &lt;PID&gt;\n</code></pre>"},{"location":"getting-started/installation/#model-not-found","title":"Model Not Found","text":"<pre><code>Model 'llama3.2' not found\n</code></pre> <p>Solution:</p> <pre><code># Pull the model\nollama pull llama3.2\n\n# Verify it's available\nollama list\n</code></pre>"},{"location":"getting-started/installation/#pnpm-not-found","title":"pnpm Not Found","text":"<pre><code># Install pnpm globally\nnpm install -g pnpm\n\n# Or using corepack (Node.js 16.10+)\ncorepack enable\ncorepack prepare pnpm@latest --activate\n</code></pre>"},{"location":"getting-started/installation/#sqlite-errors","title":"SQLite Errors","text":"<p>If you see database errors, delete the database files and restart:</p> <pre><code>rm -f data/api.db\nrm -f web-ui/data/chat.db\n</code></pre>"},{"location":"getting-started/installation/#next-steps","title":"Next Steps","text":"<ul> <li>Follow the Quick Start Guide to use the app</li> <li>Read about PDF Processing</li> <li>Learn the RAG Pipeline</li> <li>Check the API Reference</li> </ul>"},{"location":"getting-started/quickstart/","title":"Quick Start Guide","text":"<p>Get up and running with Ollama PDF RAG in 5 minutes.</p>"},{"location":"getting-started/quickstart/#prerequisites","title":"Prerequisites","text":"<ul> <li> Completed the installation</li> <li> Ollama running with models pulled</li> <li> Virtual environment activated</li> </ul>"},{"location":"getting-started/quickstart/#option-1-nextjs-ui-recommended","title":"Option 1: Next.js UI (Recommended)","text":"<p>The Next.js interface is the modern, feature-rich option.</p>"},{"location":"getting-started/quickstart/#start-both-services","title":"Start Both Services","text":"<pre><code># Easy way - uses the start script\n./start_all.sh\n\n# Or manually in two terminals:\n# Terminal 1 - Backend\npython run_api.py\n\n# Terminal 2 - Frontend\ncd web-ui &amp;&amp; pnpm dev\n</code></pre>"},{"location":"getting-started/quickstart/#open-the-app","title":"Open the App","text":"<p>Navigate to http://localhost:3000</p> <p></p>"},{"location":"getting-started/quickstart/#workflow","title":"Workflow","text":"<pre><code>1. Upload PDF     \u2192  Click \ud83d\udcce button, select PDF\n2. Select PDF     \u2192  Check \u2611\ufe0f the PDF in sidebar\n3. Ask Question   \u2192  Type in chat box, press Enter\n4. Get Answer     \u2192  Response with source citations\n</code></pre>"},{"location":"getting-started/quickstart/#option-2-streamlit-ui-classic","title":"Option 2: Streamlit UI (Classic)","text":"<p>The Streamlit interface is simpler and good for quick testing.</p>"},{"location":"getting-started/quickstart/#start-the-app","title":"Start the App","text":"<pre><code>python run.py\n</code></pre>"},{"location":"getting-started/quickstart/#open-the-app_1","title":"Open the App","text":"<p>Navigate to http://localhost:8501</p> <p></p>"},{"location":"getting-started/quickstart/#basic-usage","title":"Basic Usage","text":""},{"location":"getting-started/quickstart/#1-upload-a-pdf","title":"1. Upload a PDF","text":"<p>Next.js: - Click the \ud83d\udcce (paperclip) button in the chat input - Select your PDF file - Wait for processing (shown in toast notification)</p> <p>Streamlit: - Use the file uploader in the sidebar - Or click \"Load Sample PDF\"</p>"},{"location":"getting-started/quickstart/#2-select-pdfs-for-context","title":"2. Select PDFs for Context","text":"<p>Next.js: <pre><code>\u2610 Warranty_Book.pdf (11 chunks \u2022 1 pages)\n\u2611\ufe0f Security_Guide.pdf (45 chunks \u2022 12 pages)\n</code></pre></p> <ul> <li>Check the boxes next to PDFs you want to search</li> <li>Use \"All\" or \"None\" buttons for quick selection</li> <li>Selection persists across page refreshes</li> </ul> <p>Important</p> <p>If you don't select any PDFs and ask a document question,  you'll see a warning prompting you to select documents.</p>"},{"location":"getting-started/quickstart/#3-choose-a-model","title":"3. Choose a Model","text":"<p>Click the model selector in the chat input:</p> Model Best For <code>llama3.2</code> Fast, general purpose <code>qwen3:8b</code> Detailed reasoning, thinking mode <code>mistral</code> Balanced performance"},{"location":"getting-started/quickstart/#4-ask-questions","title":"4. Ask Questions","text":"<p>Good questions: <pre><code>\u2705 \"What are the main security recommendations?\"\n\u2705 \"Summarize section 3 of the document\"\n\u2705 \"What does the warranty cover?\"\n\u2705 \"Compare the approaches mentioned in pages 5-7\"\n</code></pre></p> <p>The system handles: <pre><code>\ud83d\udcc4 Document questions \u2192 Uses RAG with selected PDFs\n\ud83d\udcac General questions \u2192 Direct chat (no RAG needed)\n\u26a0\ufe0f Doc questions without PDFs \u2192 Shows warning\n</code></pre></p>"},{"location":"getting-started/quickstart/#5-understanding-responses","title":"5. Understanding Responses","text":"<p>Responses include:</p> <ul> <li>Answer: The main response</li> <li>Sources: Which PDF chunks were used</li> <li>Reasoning (qwen3/deepseek): Chain-of-thought process</li> </ul> <p>Example response: <pre><code>The document covers three main security aspects:\n\n1. **Authentication** - Multi-factor authentication is required...\n2. **Authorization** - Role-based access control using...\n3. **Encryption** - All data at rest uses AES-256...\n\n**Sources:**\n- Security_Guide.pdf (chunk 3)\n- Security_Guide.pdf (chunk 7)\n- Security_Guide.pdf (chunk 12)\n</code></pre></p>"},{"location":"getting-started/quickstart/#service-urls","title":"Service URLs","text":"Service URL Purpose Next.js UI http://localhost:3000 Modern chat interface Streamlit UI http://localhost:8501 Classic interface FastAPI Backend http://localhost:8001 REST API API Docs http://localhost:8001/docs Swagger UI Health Check http://localhost:8001/health Status endpoint"},{"location":"getting-started/quickstart/#example-session","title":"Example Session","text":"<p>Here's a complete example workflow:</p> <pre><code># 1. Start services\n./start_all.sh\n\n# 2. Open browser to http://localhost:3000\n\n# 3. Upload a PDF (click \ud83d\udcce)\n# \u2192 Select \"company_policy.pdf\"\n# \u2192 Wait for \"uploaded successfully!\" toast\n\n# 4. Select the PDF (check \u2611\ufe0f in sidebar)\n# \u2192 Shows: \"Documents (1/1)\"\n\n# 5. Ask a question\n# \u2192 \"What is the vacation policy?\"\n\n# 6. Get answer with sources\n# \u2192 \"According to the document, employees receive...\"\n# \u2192 Sources: company_policy.pdf (chunk 5, 8)\n\n# 7. Follow up\n# \u2192 \"What about sick leave?\"\n# \u2192 Uses same document context\n</code></pre>"},{"location":"getting-started/quickstart/#tips-for-best-results","title":"Tips for Best Results","text":""},{"location":"getting-started/quickstart/#document-preparation","title":"Document Preparation","text":"<ul> <li>Use text-based PDFs (not scanned images)</li> <li>Smaller PDFs process faster</li> <li>Split very large PDFs into sections</li> </ul>"},{"location":"getting-started/quickstart/#asking-questions","title":"Asking Questions","text":"<ul> <li>Be specific: \"What is X?\" vs \"Tell me about X\"</li> <li>Reference sections: \"In the introduction...\"</li> <li>Ask follow-ups: \"Can you explain more about...?\"</li> </ul>"},{"location":"getting-started/quickstart/#performance","title":"Performance","text":"<ul> <li>Select only needed PDFs (fewer = faster)</li> <li>Use <code>llama3.2</code> for speed, <code>qwen3:8b</code> for detail</li> <li>Clear chat history periodically</li> </ul>"},{"location":"getting-started/quickstart/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/quickstart/#no-pdfs-uploaded-yet","title":"\"No PDFs uploaded yet\"","text":"<p>\u2192 Click \ud83d\udcce and upload a PDF first</p>"},{"location":"getting-started/quickstart/#no-documents-selected","title":"\"No documents selected\"","text":"<p>\u2192 Check the \u2611\ufe0f boxes next to PDFs in sidebar</p>"},{"location":"getting-started/quickstart/#response-is-slow","title":"Response is slow","text":"<p>\u2192 Try a smaller model or select fewer PDFs</p>"},{"location":"getting-started/quickstart/#model-not-found","title":"\"Model not found\"","text":"<p>\u2192 Run <code>ollama pull &lt;model-name&gt;</code></p>"},{"location":"getting-started/quickstart/#next-steps","title":"Next Steps","text":"<ul> <li>PDF Processing - How documents are chunked</li> <li>RAG Pipeline - How retrieval works</li> <li>API Reference - Use the REST API</li> <li>Contributing - Help improve the project</li> </ul>"},{"location":"user-guide/chat-interface/","title":"Chat Interface Guide","text":"<p>Ollama PDF RAG offers two user interfaces: a modern Next.js app and a classic Streamlit interface. This guide covers both.</p>"},{"location":"user-guide/chat-interface/#nextjs-interface-recommended","title":"Next.js Interface (Recommended)","text":"<p>The Next.js interface at <code>http://localhost:3000</code> provides the full-featured experience.</p> <p></p>"},{"location":"user-guide/chat-interface/#layout","title":"Layout","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  PDF Chat                                    [GitHub] [Theme]  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                  \u2502                                             \u2502\n\u2502  \ud83d\udcc4 Documents    \u2502         Chat Messages                       \u2502\n\u2502  (1/2 selected)  \u2502                                             \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502                  \u2502         \u2502 User: What is this about?    \u2502    \u2502\n\u2502  \u2611\ufe0f Policy.pdf   \u2502         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u2502    45 chunks     \u2502                                             \u2502\n\u2502                  \u2502         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502  \u2610 Guide.pdf    \u2502         \u2502 Assistant: Based on the...   \u2502    \u2502\n\u2502    23 chunks     \u2502         \u2502 Sources: Policy.pdf (3,7)    \u2502    \u2502\n\u2502                  \u2502         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502                                             \u2502\n\u2502                  \u2502                                             \u2502\n\u2502  Today           \u2502                                             \u2502\n\u2502  \u25cb Chat 1        \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u25cb Chat 2        \u2502  \u2502 Send a message...      \ud83d\udcce qwen3:8b \u2191 \u2502  \u2502\n\u2502                  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"user-guide/chat-interface/#components","title":"Components","text":""},{"location":"user-guide/chat-interface/#sidebar-document-selection","title":"Sidebar - Document Selection","text":"<p>The sidebar shows all uploaded PDFs with checkboxes:</p> <pre><code>\ud83d\udcc4 Documents (2/3)\n\u26a0\ufe0f Select PDFs to use as context\n\n\u2611\ufe0f Security_Guide.pdf\n   45 chunks \u2022 12 pages\n\n\u2611\ufe0f Policy_Manual.pdf\n   23 chunks \u2022 8 pages\n\n\u2610 Reference.pdf\n   15 chunks \u2022 4 pages\n\n[All] [None]          \ud83d\uddd1\ufe0f\n</code></pre> Element Description Checkbox (\u2611\ufe0f/\u2610) Toggle PDF for RAG context Chunk count Number of text segments Page count Original PDF pages All/None Quick select/deselect all \ud83d\uddd1\ufe0f Delete PDF (on hover) <p>Selection Persists</p> <p>Your PDF selection is saved to localStorage and persists  across browser sessions.</p>"},{"location":"user-guide/chat-interface/#chat-history","title":"Chat History","text":"<p>Shows previous conversations grouped by date:</p> <ul> <li>Today - Chats from today</li> <li>Yesterday - Previous day</li> <li>Last 7 days - Past week</li> <li>Older - Everything else</li> </ul> <p>Click any chat to resume the conversation.</p>"},{"location":"user-guide/chat-interface/#chat-input","title":"Chat Input","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Send a message...                                    \u2502\n\u2502                                                      \u2502\n\u2502 \ud83d\udcce                         \u2699\ufe0f qwen3:8b            \u2191 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> Button Action \ud83d\udcce Upload PDF file \u2699\ufe0f Model Select Ollama model \u2191 Send message"},{"location":"user-guide/chat-interface/#features","title":"Features","text":""},{"location":"user-guide/chat-interface/#1-pdf-upload","title":"1. PDF Upload","text":"<p>Click \ud83d\udcce \u2192 Select PDF \u2192 Wait for processing</p> <p>Processing includes: 1. Save file to server 2. Extract text (UnstructuredPDFLoader) 3. Split into chunks (7500 chars) 4. Generate embeddings (nomic-embed-text) 5. Store in ChromaDB</p>"},{"location":"user-guide/chat-interface/#2-document-selection","title":"2. Document Selection","text":"<p>Pre-chat Selection: Select PDFs BEFORE sending your first message.</p> <pre><code>\u2705 Correct workflow:\n1. Upload PDFs\n2. Select relevant PDFs (\u2611\ufe0f)\n3. Ask question\n\n\u274c Won't work well:\n1. Upload PDFs\n2. Ask question immediately\n3. (No PDFs selected!)\n</code></pre>"},{"location":"user-guide/chat-interface/#3-question-classification","title":"3. Question Classification","text":"<p>The system automatically detects your intent:</p> Question Type Detection Action Document query \"what does the document say...\" Uses RAG General chat \"what is machine learning?\" Direct LLM Doc query, no selection Document keywords, no PDFs Shows warning <p>Warning message when no PDFs selected: <pre><code>\u26a0\ufe0f No documents selected\n\nIt looks like your question might be about a document,\nbut you haven't selected any PDFs to search.\n\nTo get answers from your documents:\n1. Look at the sidebar on the left\n2. Check the boxes next to the PDFs you want to use\n3. Then ask your question again\n</code></pre></p>"},{"location":"user-guide/chat-interface/#4-model-selection","title":"4. Model Selection","text":"<p>Switch between available Ollama models:</p> Model Size Best For <code>llama3.2</code> 2GB Fast responses <code>qwen3:8b</code> 5GB Deep reasoning <code>mistral</code> 4GB Balanced <code>deepseek-r1</code> 4GB Complex analysis <p>Models with \"thinking\" support (<code>qwen3</code>, <code>deepseek-r1</code>) show their reasoning process.</p>"},{"location":"user-guide/chat-interface/#5-chat-persistence","title":"5. Chat Persistence","text":"<ul> <li>Chats auto-save to SQLite database</li> <li>Resume any previous conversation</li> <li>Delete individual chats or all history</li> <li>Chat titles auto-generated from first message</li> </ul>"},{"location":"user-guide/chat-interface/#6-response-streaming","title":"6. Response Streaming","text":"<p>Responses stream word-by-word with: - Reasoning steps (for thinking models) - Main answer text - Source citations</p>"},{"location":"user-guide/chat-interface/#streamlit-interface-classic","title":"Streamlit Interface (Classic)","text":"<p>The Streamlit interface at <code>http://localhost:8501</code> provides a simpler experience.</p> <p></p>"},{"location":"user-guide/chat-interface/#layout_1","title":"Layout","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Ollama PDF RAG                                         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502               \u2502                                         \u2502\n\u2502  \ud83d\udcc4 Upload    \u2502              PDF Preview                \u2502\n\u2502  [Browse]     \u2502         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510           \u2502\n\u2502               \u2502         \u2502                  \u2502           \u2502\n\u2502  \ud83e\udd16 Model     \u2502         \u2502   Page 1 of 10   \u2502           \u2502\n\u2502  [llama3.2 \u25bc] \u2502         \u2502                  \u2502           \u2502\n\u2502               \u2502         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2502\n\u2502  \ud83d\udd0d Zoom      \u2502                                         \u2502\n\u2502  [\u2500\u2500\u2500\u2500\u25cf\u2500\u2500\u2500\u2500]  \u2502                                         \u2502\n\u2502               \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\n\u2502  \u274c Delete    \u2502                                         \u2502\n\u2502               \u2502              Chat Area                  \u2502\n\u2502               \u2502                                         \u2502\n\u2502               \u2502  User: What is this document about?    \u2502\n\u2502               \u2502                                         \u2502\n\u2502               \u2502  Assistant: This document covers...    \u2502\n\u2502               \u2502                                         \u2502\n\u2502               \u2502  [Type your question here...]          \u2502\n\u2502               \u2502                                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"user-guide/chat-interface/#features_1","title":"Features","text":"Feature Description File Upload Drag &amp; drop or browse Sample PDF Quick start with included samples Model Selection Dropdown of available models PDF Viewer Preview with zoom control Chat History In-session message history Delete Collection Clear vector database"},{"location":"user-guide/chat-interface/#usage","title":"Usage","text":"<ol> <li>Upload PDF - Use sidebar uploader or sample</li> <li>Select Model - Choose from dropdown</li> <li>Adjust Zoom - Slider for PDF visibility</li> <li>Ask Questions - Type in chat input</li> <li>Clear Context - Delete Collection when switching PDFs</li> </ol>"},{"location":"user-guide/chat-interface/#comparison","title":"Comparison","text":"Feature Next.js Streamlit Modern UI \u2705 \u274c Chat persistence \u2705 \u274c Multi-PDF selection \u2705 \u274c Question classification \u2705 \u274c PDF preview \u274c \u2705 Response streaming \u2705 \u2705 Mobile friendly \u2705 \u26a0\ufe0f Setup complexity Medium Low"},{"location":"user-guide/chat-interface/#keyboard-shortcuts","title":"Keyboard Shortcuts","text":""},{"location":"user-guide/chat-interface/#nextjs","title":"Next.js","text":"Shortcut Action <code>Enter</code> Send message <code>Shift + Enter</code> New line in message"},{"location":"user-guide/chat-interface/#streamlit","title":"Streamlit","text":"Shortcut Action <code>Enter</code> Send message <code>Ctrl + K</code> Clear chat"},{"location":"user-guide/chat-interface/#best-practices","title":"Best Practices","text":""},{"location":"user-guide/chat-interface/#for-best-results","title":"For Best Results","text":"<ol> <li>Select specific PDFs - Don't use \"All\" unless needed</li> <li>Ask focused questions - One topic at a time</li> <li>Use thinking models - For complex analysis</li> <li>Check sources - Verify which chunks were used</li> </ol>"},{"location":"user-guide/chat-interface/#common-patterns","title":"Common Patterns","text":"<pre><code># Summary request\n\"Summarize the key points in this document\"\n\n# Specific lookup\n\"What does section 3.2 say about authentication?\"\n\n# Comparison\n\"How does chapter 1 compare to chapter 5?\"\n\n# Extraction\n\"List all the dates mentioned in this document\"\n</code></pre>"},{"location":"user-guide/chat-interface/#troubleshooting","title":"Troubleshooting","text":"Issue Solution Slow responses Use smaller model, fewer PDFs Wrong sources Be more specific in question Missing context Select more PDFs No response Check Ollama is running"},{"location":"user-guide/pdf-processing/","title":"PDF Processing","text":"<p>This guide explains how Ollama PDF RAG processes PDF documents for retrieval.</p>"},{"location":"user-guide/pdf-processing/#processing-pipeline","title":"Processing Pipeline","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   PDF File   \u2502\u2500\u2500\u2500\u25b6\u2502    Load &amp;    \u2502\u2500\u2500\u2500\u25b6\u2502    Split     \u2502\u2500\u2500\u2500\u25b6\u2502   Generate   \u2502\n\u2502   Upload     \u2502    \u2502    Parse     \u2502    \u2502    Chunks    \u2502    \u2502  Embeddings  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                                    \u2502\n                                                                    \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Ready to   \u2502\u25c0\u2500\u2500\u2500\u2502    Save      \u2502\u25c0\u2500\u2500\u2500\u2502    Store     \u2502\u25c0\u2500\u2500\u2500\u2502    Add       \u2502\n\u2502    Query     \u2502    \u2502   Metadata   \u2502    \u2502   Vectors    \u2502    \u2502   Metadata   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"user-guide/pdf-processing/#step-1-file-upload","title":"Step 1: File Upload","text":""},{"location":"user-guide/pdf-processing/#api-endpoint","title":"API Endpoint","text":"<pre><code>POST http://localhost:8001/api/v1/pdfs/upload\nContent-Type: multipart/form-data\n\nfile: &lt;PDF file&gt;\n</code></pre>"},{"location":"user-guide/pdf-processing/#storage-location","title":"Storage Location","text":"<pre><code>data/pdfs/uploads/\n\u2514\u2500\u2500 pdf_{hash}_{original_name}.pdf\n</code></pre> <p>Each uploaded PDF gets a unique ID based on filename + timestamp hash.</p>"},{"location":"user-guide/pdf-processing/#step-2-document-loading","title":"Step 2: Document Loading","text":"<p>We use LangChain's <code>UnstructuredPDFLoader</code> to extract text:</p> <pre><code>from langchain_community.document_loaders import UnstructuredPDFLoader\n\nloader = UnstructuredPDFLoader(file_path)\ndocuments = loader.load()\n</code></pre>"},{"location":"user-guide/pdf-processing/#what-gets-extracted","title":"What Gets Extracted","text":"Element Handled Text content \u2705 Headers/titles \u2705 Lists \u2705 Tables (basic) \u2705 Images \u274c Scanned text \u274c (needs OCR)"},{"location":"user-guide/pdf-processing/#document-object","title":"Document Object","text":"<pre><code>Document(\n    page_content=\"The extracted text from the PDF...\",\n    metadata={\n        \"source\": \"/path/to/file.pdf\",\n        \"page\": 1\n    }\n)\n</code></pre>"},{"location":"user-guide/pdf-processing/#step-3-text-chunking","title":"Step 3: Text Chunking","text":"<p>Large documents are split into smaller chunks for efficient retrieval:</p> <pre><code>from langchain_text_splitters import RecursiveCharacterTextSplitter\n\nsplitter = RecursiveCharacterTextSplitter(\n    chunk_size=7500,\n    chunk_overlap=100,\n    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n)\n\nchunks = splitter.split_documents(documents)\n</code></pre>"},{"location":"user-guide/pdf-processing/#chunking-strategy","title":"Chunking Strategy","text":"<pre><code>Original Document (20,000 chars)\n        \u2502\n        \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                   Chunk 1 (7500)                    \u2502\n\u2502 \u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 \u2502\n\u2502                                        \u25c4\u2500\u2500overlap\u2500\u2500\u25ba\u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                                 \u2502                   Chunk 2 (7500)                    \u2502\n                                 \u2502 \u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 \u2502\n                                 \u2502                                        \u25c4\u2500\u2500overlap\u2500\u2500\u25ba\u2502\n                                 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                                  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                                                                  \u2502   Chunk 3 (5000)    \u2502\n                                                                  \u2502 \u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 \u2502\n                                                                  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"user-guide/pdf-processing/#configuration","title":"Configuration","text":"Parameter Value Description <code>chunk_size</code> 7500 Maximum characters per chunk <code>chunk_overlap</code> 100 Characters shared between chunks <code>separators</code> <code>[\"\\n\\n\", \"\\n\", \" \", \"\"]</code> Split priority"},{"location":"user-guide/pdf-processing/#why-these-settings","title":"Why These Settings?","text":"<ul> <li>7500 chars: Large enough for context, small enough for precise retrieval</li> <li>100 overlap: Preserves context at boundaries</li> <li>Recursive splitting: Respects document structure (paragraphs &gt; lines &gt; words)</li> </ul>"},{"location":"user-guide/pdf-processing/#step-4-metadata-enhancement","title":"Step 4: Metadata Enhancement","text":"<p>Each chunk gets enriched metadata:</p> <pre><code>for i, chunk in enumerate(chunks):\n    chunk.metadata.update({\n        \"pdf_id\": \"pdf_123456\",\n        \"pdf_name\": \"Security_Guide.pdf\",\n        \"chunk_index\": i,\n        \"source_file\": \"Security_Guide.pdf\"\n    })\n</code></pre>"},{"location":"user-guide/pdf-processing/#metadata-schema","title":"Metadata Schema","text":"<pre><code>{\n    \"source\": \"/path/to/file.pdf\",      # Original file path\n    \"page\": 5,                          # Page number (if available)\n    \"pdf_id\": \"pdf_123456\",             # Unique PDF identifier\n    \"pdf_name\": \"Security_Guide.pdf\",   # Display name\n    \"chunk_index\": 3,                   # Chunk sequence number\n    \"source_file\": \"Security_Guide.pdf\" # Original filename\n}\n</code></pre>"},{"location":"user-guide/pdf-processing/#step-5-embedding-generation","title":"Step 5: Embedding Generation","text":"<p>Chunks are converted to vectors using Ollama's embedding model:</p> <pre><code>from langchain_ollama import OllamaEmbeddings\n\nembeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n</code></pre>"},{"location":"user-guide/pdf-processing/#embedding-details","title":"Embedding Details","text":"Property Value Model nomic-embed-text Dimensions 768 Type Float32"},{"location":"user-guide/pdf-processing/#process","title":"Process","text":"<pre><code>\"The security policy requires...\"  \u2500\u2500\u2500\u25b6  [0.023, -0.156, 0.892, ...]\n                                              768 dimensions\n</code></pre>"},{"location":"user-guide/pdf-processing/#step-6-vector-storage","title":"Step 6: Vector Storage","text":"<p>Embeddings are stored in ChromaDB:</p> <pre><code>from langchain_chroma import Chroma\n\nvector_db = Chroma.from_documents(\n    documents=chunks,\n    embedding=embeddings,\n    collection_name=f\"pdf_{hash}\",\n    persist_directory=\"data/vectors\"\n)\n</code></pre>"},{"location":"user-guide/pdf-processing/#collection-structure","title":"Collection Structure","text":"<pre><code>data/vectors/\n\u251c\u2500\u2500 chroma.sqlite3              # Metadata database\n\u2514\u2500\u2500 collections/\n    \u251c\u2500\u2500 pdf_123456/             # Collection per PDF\n    \u2502   \u251c\u2500\u2500 data/\n    \u2502   \u2514\u2500\u2500 metadata/\n    \u2514\u2500\u2500 pdf_789012/\n        \u251c\u2500\u2500 data/\n        \u2514\u2500\u2500 metadata/\n</code></pre> <p>Each PDF gets its own collection, enabling: - Selective querying (specific PDFs) - Easy deletion - Isolation between documents</p>"},{"location":"user-guide/pdf-processing/#step-7-metadata-persistence","title":"Step 7: Metadata Persistence","text":"<p>PDF metadata is saved to SQLite:</p> <pre><code>pdf_metadata = PDFMetadata(\n    pdf_id=\"pdf_123456\",\n    name=\"Security_Guide.pdf\",\n    collection_name=\"pdf_123456\",\n    upload_timestamp=datetime.now(),\n    doc_count=15,           # Number of chunks\n    page_count=12,          # Original pages\n    is_sample=False,\n    file_path=\"/data/pdfs/uploads/pdf_123456_Security_Guide.pdf\"\n)\ndb.add(pdf_metadata)\ndb.commit()\n</code></pre>"},{"location":"user-guide/pdf-processing/#database-schema","title":"Database Schema","text":"<pre><code>CREATE TABLE pdf_metadata (\n    id INTEGER PRIMARY KEY,\n    pdf_id TEXT UNIQUE NOT NULL,\n    name TEXT NOT NULL,\n    collection_name TEXT NOT NULL,\n    upload_timestamp DATETIME,\n    doc_count INTEGER,\n    page_count INTEGER,\n    is_sample BOOLEAN DEFAULT FALSE,\n    file_path TEXT\n);\n</code></pre>"},{"location":"user-guide/pdf-processing/#api-endpoints","title":"API Endpoints","text":""},{"location":"user-guide/pdf-processing/#upload-pdf","title":"Upload PDF","text":"<pre><code>POST /api/v1/pdfs/upload\nContent-Type: multipart/form-data\n\nResponse:\n{\n  \"pdf_id\": \"pdf_123456\",\n  \"name\": \"Security_Guide.pdf\",\n  \"collection_name\": \"pdf_123456\",\n  \"doc_count\": 15,\n  \"page_count\": 12,\n  \"upload_timestamp\": \"2024-12-19T18:00:00Z\"\n}\n</code></pre>"},{"location":"user-guide/pdf-processing/#list-pdfs","title":"List PDFs","text":"<pre><code>GET /api/v1/pdfs\n\nResponse:\n[\n  {\n    \"pdf_id\": \"pdf_123456\",\n    \"name\": \"Security_Guide.pdf\",\n    \"collection_name\": \"pdf_123456\",\n    \"upload_timestamp\": \"2024-12-19T18:00:00Z\",\n    \"doc_count\": 15,\n    \"page_count\": 12,\n    \"is_sample\": false\n  }\n]\n</code></pre>"},{"location":"user-guide/pdf-processing/#delete-pdf","title":"Delete PDF","text":"<pre><code>DELETE /api/v1/pdfs/{pdf_id}\n\nResponse:\n{\n  \"message\": \"PDF deleted successfully\"\n}\n</code></pre> <p>Deletion removes: 1. PDF file from disk 2. Vector collection from ChromaDB 3. Metadata from SQLite</p>"},{"location":"user-guide/pdf-processing/#processing-statistics","title":"Processing Statistics","text":"<p>For a typical document:</p> Document Pages Size Chunks Processing Time Small PDF 5 200KB 3-5 ~5 seconds Medium PDF 20 1MB 10-20 ~15 seconds Large PDF 100 10MB 50-100 ~60 seconds"},{"location":"user-guide/pdf-processing/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user-guide/pdf-processing/#failed-to-load-pdf","title":"\"Failed to load PDF\"","text":"<ul> <li>Check file is valid PDF (not corrupted)</li> <li>Ensure file is text-based (not scanned image)</li> <li>Verify file permissions</li> </ul>"},{"location":"user-guide/pdf-processing/#no-chunks-created","title":"\"No chunks created\"","text":"<ul> <li>PDF might be empty or image-only</li> <li>Check if text extraction worked</li> <li>Try a different PDF</li> </ul>"},{"location":"user-guide/pdf-processing/#embedding-failed","title":"\"Embedding failed\"","text":"<ul> <li>Verify Ollama is running</li> <li>Check <code>nomic-embed-text</code> is pulled</li> <li>Look for memory issues</li> </ul>"},{"location":"user-guide/pdf-processing/#chromadb-error","title":"\"ChromaDB error\"","text":"<ul> <li>Check disk space for vectors</li> <li>Verify write permissions on <code>data/vectors</code></li> <li>Try deleting and re-uploading</li> </ul>"},{"location":"user-guide/pdf-processing/#best-practices","title":"Best Practices","text":""},{"location":"user-guide/pdf-processing/#optimal-pdf-characteristics","title":"Optimal PDF Characteristics","text":"<ul> <li>\u2705 Text-based (not scanned)</li> <li>\u2705 Well-structured (headings, paragraphs)</li> <li>\u2705 Under 100 pages (for speed)</li> <li>\u2705 Clear language (not heavily formatted)</li> </ul>"},{"location":"user-guide/pdf-processing/#pre-processing-tips","title":"Pre-processing Tips","text":"<ol> <li>Split large PDFs - Break into chapters/sections</li> <li>OCR scanned docs - Use Adobe/external tool first</li> <li>Remove images - If not needed for context</li> <li>Clean formatting - Remove excessive headers/footers</li> </ol>"},{"location":"user-guide/rag-pipeline/","title":"RAG Pipeline","text":"<p>This guide explains how the Retrieval-Augmented Generation (RAG) pipeline works in Ollama PDF RAG.</p>"},{"location":"user-guide/rag-pipeline/#overview","title":"Overview","text":"<p>RAG combines the knowledge in your documents with the reasoning capabilities of language models. Here's the complete flow:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                              RAG PIPELINE                                    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                             \u2502\n\u2502  User Question                                                              \u2502\n\u2502       \u2502                                                                     \u2502\n\u2502       \u25bc                                                                     \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                   \u2502\n\u2502  \u2502  Question   \u2502\u2500\u2500\u2500\u2500\u25b6\u2502   Multi-    \u2502\u2500\u2500\u2500\u2500\u25b6\u2502   Vector    \u2502                   \u2502\n\u2502  \u2502 Classifier  \u2502     \u2502   Query     \u2502     \u2502   Search    \u2502                   \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502  Generator  \u2502     \u2502  (ChromaDB) \u2502                   \u2502\n\u2502       \u2502              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                   \u2502\n\u2502       \u2502                    \u2502                    \u2502                          \u2502\n\u2502       \u2502              \u250c\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2510             \u2502                          \u2502\n\u2502       \u2502              \u2502 Query 1   \u2502             \u2502                          \u2502\n\u2502       \u2502              \u2502 Query 2   \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u25b6 Relevant Chunks       \u2502\n\u2502       \u2502              \u2502 Query 3   \u2502             \u2502                          \u2502\n\u2502       \u2502              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518             \u2502                          \u2502\n\u2502       \u2502                                        \u2502                          \u2502\n\u2502       \u25bc                                        \u25bc                          \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u2502\n\u2502  \u2502   Direct    \u2502     \u2502         Context Assembly            \u2502              \u2502\n\u2502  \u2502    LLM      \u2502     \u2502  [Source: doc1.pdf] chunk content   \u2502              \u2502\n\u2502  \u2502  Response   \u2502     \u2502  [Source: doc2.pdf] chunk content   \u2502              \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502  [Source: doc1.pdf] chunk content   \u2502              \u2502\n\u2502       \u2502              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2502\n\u2502       \u2502                              \u2502                                     \u2502\n\u2502       \u2502                              \u25bc                                     \u2502\n\u2502       \u2502              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u2502\n\u2502       \u2502              \u2502           LLM Generation            \u2502              \u2502\n\u2502       \u2502              \u2502  - Chain-of-thought reasoning       \u2502              \u2502\n\u2502       \u2502              \u2502  - Source citation                  \u2502              \u2502\n\u2502       \u2502              \u2502  - Thinking mode (if supported)     \u2502              \u2502\n\u2502       \u2502              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2502\n\u2502       \u2502                              \u2502                                     \u2502\n\u2502       \u25bc                              \u25bc                                     \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u2502\n\u2502  \u2502                    Final Response                        \u2502              \u2502\n\u2502  \u2502  Answer text + Source citations + Reasoning steps        \u2502              \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2502\n\u2502                                                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"user-guide/rag-pipeline/#step-1-question-classification","title":"Step 1: Question Classification","text":"<p>Before processing, the system classifies the question:</p> <pre><code>def needsDocumentContext(question: str) -&gt; bool:\n    document_keywords = [\n        \"document\", \"pdf\", \"file\", \"page\", \"section\",\n        \"according to\", \"based on\", \"what does\", \"summarize\",\n        \"the document\", \"the file\", \"uploaded\", \"in the\"\n    ]\n    return any(keyword in question.lower() for keyword in document_keywords)\n</code></pre> Question Classification Action \"What does the document say about X?\" Document query Use RAG \"What is machine learning?\" General query Direct LLM \"Summarize the warranty terms\" (no PDFs) Document, no context Show warning"},{"location":"user-guide/rag-pipeline/#step-2-multi-query-generation","title":"Step 2: Multi-Query Generation","text":"<p>For document queries, we generate multiple search queries to improve retrieval:</p> <pre><code># Original question\n\"What are the security requirements?\"\n\n# Generated alternatives\n1. \"What security requirements are documented?\"\n2. \"What security measures does the document mandate?\"\n3. \"What are the security specifications mentioned?\"\n</code></pre> <p>This overcomes limitations of single-query similarity search by exploring different phrasings.</p> <p>Implementation:</p> <pre><code>QUERY_PROMPT = PromptTemplate(\n    input_variables=[\"question\"],\n    template=\"\"\"You are an AI language model assistant. Generate 2\n    different versions of the given user question to retrieve relevant \n    documents from a vector database.\n\n    Original question: {question}\"\"\"\n)\n\nretriever = MultiQueryRetriever.from_llm(\n    vector_db.as_retriever(search_kwargs={\"k\": 3}),\n    llm,\n    prompt=QUERY_PROMPT\n)\n</code></pre>"},{"location":"user-guide/rag-pipeline/#step-3-vector-search","title":"Step 3: Vector Search","text":"<p>Each generated query searches the ChromaDB vector database:</p> <pre><code>Query 1 \u2500\u2500\u25b6 ChromaDB \u2500\u2500\u25b6 [chunk_a, chunk_b, chunk_c]\nQuery 2 \u2500\u2500\u25b6 ChromaDB \u2500\u2500\u25b6 [chunk_a, chunk_d, chunk_e]\nQuery 3 \u2500\u2500\u25b6 ChromaDB \u2500\u2500\u25b6 [chunk_b, chunk_f, chunk_g]\n                              \u2502\n                              \u25bc\n                    Combined: [chunk_a, chunk_b, chunk_c,\n                               chunk_d, chunk_e, chunk_f, chunk_g]\n</code></pre> <p>Search Parameters:</p> Parameter Value Description k 3 Chunks per query per PDF Collection Per-PDF Each PDF has its own collection Embeddings nomic-embed-text 768-dim vectors <p>Multi-PDF Search:</p> <p>When multiple PDFs are selected, we search each collection:</p> <pre><code>for pdf in selected_pdfs:\n    vector_db = Chroma(\n        persist_directory=persist_directory,\n        embedding_function=embeddings,\n        collection_name=pdf.collection_name\n    )\n    docs = retriever.invoke(question)\n    all_docs.extend(docs)\n</code></pre>"},{"location":"user-guide/rag-pipeline/#step-4-context-assembly","title":"Step 4: Context Assembly","text":"<p>Retrieved chunks are formatted with source labels:</p> <pre><code>context_parts = []\nfor doc in all_docs[:10]:  # Top 10 chunks\n    source = doc.metadata.get(\"pdf_name\", \"Unknown\")\n    context_parts.append(f\"[Source: {source}]\\n{doc.page_content}\\n\")\n\nformatted_context = \"\\n---\\n\".join(context_parts)\n</code></pre> <p>Example Context:</p> <pre><code>[Source: Security_Guide.pdf]\nAuthentication requirements include multi-factor authentication (MFA)\nfor all user accounts. Password policies must enforce...\n\n---\n\n[Source: Security_Guide.pdf]\nAuthorization uses role-based access control (RBAC) with the following\nroles defined: Administrator, Manager, User, Guest...\n\n---\n\n[Source: Policy_Manual.pdf]\nAll security incidents must be reported within 24 hours using the\nincident response form located in Appendix B...\n</code></pre>"},{"location":"user-guide/rag-pipeline/#step-5-llm-generation","title":"Step 5: LLM Generation","text":"<p>The formatted context and question are sent to the LLM:</p>"},{"location":"user-guide/rag-pipeline/#standard-mode","title":"Standard Mode","text":"<pre><code>template = \"\"\"Answer the question based ONLY on the following context.\nEach section is marked with its source document.\n\nUse chain-of-thought reasoning:\n1. Identify relevant parts of the context\n2. Analyze information from each source\n3. Synthesize a comprehensive answer\n4. Cite sources for each piece of information\n\nContext:\n{context}\n\nQuestion: {question}\n\nThink step-by-step and provide your answer with source citations:\"\"\"\n</code></pre>"},{"location":"user-guide/rag-pipeline/#thinking-mode-qwen3-deepseek-r1","title":"Thinking Mode (qwen3, deepseek-r1)","text":"<p>For models that support thinking, we use enhanced prompting:</p> <pre><code>if supports_thinking:\n    response = ollama.chat(\n        model=model,\n        messages=[\n            {\"role\": \"system\", \"content\": cot_system_message},\n            {\"role\": \"user\", \"content\": question}\n        ],\n        think=True,  # Enable thinking mode\n        stream=False\n    )\n\n    # Capture thinking process\n    if response.message.thinking:\n        reasoning_steps.append(f\"\ud83d\udca1 Model's thinking: {response.message.thinking[:500]}\")\n</code></pre>"},{"location":"user-guide/rag-pipeline/#step-6-response-formatting","title":"Step 6: Response Formatting","text":"<p>The final response includes:</p> <pre><code>{\n  \"answer\": \"Based on the Security Guide, authentication requires...\",\n  \"sources\": [\n    {\"pdf_name\": \"Security_Guide.pdf\", \"pdf_id\": \"pdf_123\", \"chunk_index\": 3},\n    {\"pdf_name\": \"Security_Guide.pdf\", \"pdf_id\": \"pdf_123\", \"chunk_index\": 7},\n    {\"pdf_name\": \"Policy_Manual.pdf\", \"pdf_id\": \"pdf_456\", \"chunk_index\": 2}\n  ],\n  \"metadata\": {\n    \"model_used\": \"qwen3:8b\",\n    \"chunks_retrieved\": 10,\n    \"pdfs_queried\": 2,\n    \"reasoning_steps\": [\n      \"\ud83d\udcda Searching across 2 PDF(s)\",\n      \"\ud83d\udd0d Generating alternative queries...\",\n      \"\u2705 Found 5 chunks in Security_Guide.pdf\",\n      \"\u2705 Found 3 chunks in Policy_Manual.pdf\",\n      \"\ud83d\udcad Generating answer...\",\n      \"\u2728 Answer generated!\"\n    ]\n  }\n}\n</code></pre>"},{"location":"user-guide/rag-pipeline/#reasoning-steps","title":"Reasoning Steps","text":"<p>The pipeline logs progress for transparency:</p> Step Emoji Description PDF Discovery \ud83d\udcda Identifies selected PDFs Model Init \ud83e\udd16 Loads the LLM Query Generation \ud83d\udd0d Creates alternative queries Retrieval \ud83d\udcc4 Searches each PDF Chunk Count \u2705 Reports chunks found Total \ud83d\udcca Summarizes retrieval Context \ud83d\udd17 Shows chunks used Generation \ud83d\udcad LLM processing Thinking \ud83e\udde0 For thinking models Chain-of-thought \ud83d\udca1 Model's reasoning Complete \u2728 Success"},{"location":"user-guide/rag-pipeline/#configuration","title":"Configuration","text":""},{"location":"user-guide/rag-pipeline/#chunk-settings","title":"Chunk Settings","text":"<pre><code>DocumentProcessor(\n    chunk_size=7500,    # Characters per chunk\n    chunk_overlap=100   # Overlap between chunks\n)\n</code></pre> Setting Value Rationale chunk_size 7500 Balances context vs. precision chunk_overlap 100 Preserves cross-boundary context"},{"location":"user-guide/rag-pipeline/#retrieval-settings","title":"Retrieval Settings","text":"<pre><code>retriever = vector_db.as_retriever(\n    search_kwargs={\"k\": 3}  # Top 3 chunks per query\n)\n</code></pre>"},{"location":"user-guide/rag-pipeline/#model-settings","title":"Model Settings","text":"<pre><code># Thinking-enabled models\nthinking_models = ['qwen3', 'deepseek-r1', 'qwen', 'deepseek']\n</code></pre>"},{"location":"user-guide/rag-pipeline/#performance-considerations","title":"Performance Considerations","text":""},{"location":"user-guide/rag-pipeline/#speed-optimization","title":"Speed Optimization","text":"Factor Impact Solution Many PDFs Slower Select only needed PDFs Large chunks More tokens Reduce chunk_size Complex queries Multiple LLM calls Use faster models"},{"location":"user-guide/rag-pipeline/#quality-optimization","title":"Quality Optimization","text":"Factor Impact Solution Small chunks Missing context Increase chunk_size Few results Incomplete answers Increase k value Poor retrieval Wrong chunks Use thinking models"},{"location":"user-guide/rag-pipeline/#api-endpoint","title":"API Endpoint","text":"<pre><code>POST /api/v1/query\nContent-Type: application/json\n\n{\n  \"question\": \"What are the security requirements?\",\n  \"model\": \"qwen3:8b\",\n  \"pdf_ids\": [\"pdf_123\", \"pdf_456\"],\n  \"session_id\": \"optional-session-id\"\n}\n</code></pre> <p>Response:</p> <pre><code>{\n  \"answer\": \"The security requirements include...\",\n  \"sources\": [...],\n  \"metadata\": {...},\n  \"session_id\": \"generated-or-provided\",\n  \"message_id\": 42\n}\n</code></pre>"},{"location":"user-guide/rag-pipeline/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user-guide/rag-pipeline/#found-0-relevant-chunks","title":"\"Found 0 relevant chunks\"","text":"<ul> <li>Check if PDFs are properly processed</li> <li>Verify embeddings were created</li> <li>Try rephrasing the question</li> </ul>"},{"location":"user-guide/rag-pipeline/#slow-retrieval","title":"Slow Retrieval","text":"<ul> <li>Reduce number of selected PDFs</li> <li>Use SSD storage for ChromaDB</li> <li>Check Ollama server performance</li> </ul>"},{"location":"user-guide/rag-pipeline/#poor-quality-answers","title":"Poor Quality Answers","text":"<ul> <li>Use more specific questions</li> <li>Try thinking-enabled models</li> <li>Check if relevant chunks are being retrieved</li> </ul>"}]}